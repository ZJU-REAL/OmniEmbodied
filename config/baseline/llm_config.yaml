# LLM配置文件
extends: "base_config"

# LLM推理模式设置
mode: "api"

# API调用配置
api:
  # 当前使用的提供商
  provider: "qwen7b"

  # 供应商配置（统一结构）
  providers:
    volcengine:
      model: "deepseek-r1-250528"
      temperature: 0.1
      max_tokens: 512
      api_key: "${VOLCENGINE_API_KEY}"
      endpoint: "https://ark.cn-beijing.volces.com/api/v3"

    bailian:
      model: "qwen2.5-72b-instruct"
      temperature: 0.1
      max_tokens: 512
      api_key: "${BAILIAN_API_KEY}"
      endpoint: "https://dashscope.aliyuncs.com/compatible-mode/v1"
      enable_thinking: false

    deepseek:
      model: "deepseek-chat"
      temperature: 0.1
      max_tokens: 512
      api_key: "sk-ec0c6aa1a50a49b99ae1ba48eb46cc56"
      endpoint: "https://api.deepseek.com"

    qwen3b:
      model: "Qwen2.5-3B-Instruct"
      temperature: 0.3
      max_tokens: 512
      api_key: "dummy_key"
      endpoint: "http://10.130.129.18:8003/v1"
      extends:
        # 支持单智能体和多智能体格式的通用正则表达式
        guided_regex: "Thought: .+\\n(?:Agnet_1_Action|Agent_1_Action|Agent_2_Action): [A-Z_]+(?:\\s+[a-zA-Z0-9_]+)*(?:\\n(?:Agent_1_Action|Agent_2_Action): [A-Z_]+(?:\\s+[a-zA-Z0-9_]+)*)?"
        stop_tokens: ["\n\n","Execution Result"]

    qwen7b:
      model: "Qwen2.5-7B-Instruct"
      temperature: 0.3
      max_tokens: 512
      api_key: "dummy_key"
      endpoint: "http://10.130.129.18:8007/v1"
      extends:
        # 支持单智能体和多智能体格式的通用正则表达式
        guided_regex: "Thought: .+\\n(?:Agnet_1_Action|Agent_1_Action|Agent_2_Action): [A-Z_]+(?:\\s+[a-zA-Z0-9_]+)*(?:\\n(?:Agent_1_Action|Agent_2_Action): [A-Z_]+(?:\\s+[a-zA-Z0-9_]+)*)?"
        stop_tokens: ["\n\n","Execution Result"]


# VLLM本地推理配置
vllm:
  model_path: "/path/to/model"
  temperature: 0.1
  max_tokens: 4096
  tensor_parallel_size: 1
  gpu_memory_utilization: 0.9

# LLM参数配置
parameters:
  send_history: false