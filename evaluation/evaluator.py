#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä»»åŠ¡è¯„æµ‹å™¨ä¸»ç¨‹åº
æ”¯æŒå››ç§è¯„æµ‹æ¨¡å¼ï¼š
1. å•æ™ºèƒ½ä½“é€ä¸ªè¯„æµ‹ (single_sequential)
2. å•æ™ºèƒ½ä½“æ··åˆè¯„æµ‹ (single_combined)
3. å¤šæ™ºèƒ½ä½“é€ä¸ªè¯„æµ‹ (multi_sequential)
4. å¤šæ™ºèƒ½ä½“æ··åˆè¯„æµ‹ (multi_combined)

ä½¿ç”¨æ–¹æ³•:
python evaluator.py --mode single_sequential --scenario 00001
python evaluator.py --config custom_evaluator_config.yaml
"""

import os
import sys
import argparse
import logging
from typing import Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(project_root)

from utils.task_evaluator import TaskEvaluator
from utils.parallel_task_evaluator import ParallelTaskEvaluator
from config import ConfigManager


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="ä»»åŠ¡è¯„æµ‹å™¨ - æ”¯æŒå…­ç§è¯„æµ‹æ¨¡å¼",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
è¯„æµ‹æ¨¡å¼è¯´æ˜:
  single_sequential   - å•æ™ºèƒ½ä½“é€ä¸ªè¯„æµ‹ï¼šåªåŠ è½½agent1ï¼Œæ¯ä¸ªå­ä»»åŠ¡ç‹¬ç«‹æ‰§è¡Œ
  single_combined     - å•æ™ºèƒ½ä½“æ··åˆè¯„æµ‹ï¼šåªåŠ è½½agent1ï¼Œæ‰€æœ‰å­ä»»åŠ¡æ‹¼æ¥æ‰§è¡Œ
  single_independent  - å•æ™ºèƒ½ä½“ç‹¬ç«‹è¯„æµ‹ï¼šåªåŠ è½½agent1ï¼Œæ¯ä¸ªå­ä»»åŠ¡åœ¨å…¨æ–°ç¯å¢ƒä¸­æ‰§è¡Œ
  multi_sequential    - å¤šæ™ºèƒ½ä½“é€ä¸ªè¯„æµ‹ï¼šåŠ è½½æ‰€æœ‰æ™ºèƒ½ä½“ï¼Œæ¯ä¸ªå­ä»»åŠ¡ç‹¬ç«‹æ‰§è¡Œ
  multi_combined      - å¤šæ™ºèƒ½ä½“æ··åˆè¯„æµ‹ï¼šåŠ è½½æ‰€æœ‰æ™ºèƒ½ä½“ï¼Œæ‰€æœ‰å­ä»»åŠ¡æ‹¼æ¥æ‰§è¡Œ
  multi_independent   - å¤šæ™ºèƒ½ä½“ç‹¬ç«‹è¯„æµ‹ï¼šåŠ è½½æ‰€æœ‰æ™ºèƒ½ä½“ï¼Œæ¯ä¸ªå­ä»»åŠ¡åœ¨å…¨æ–°ç¯å¢ƒä¸­æ‰§è¡Œ

ç¤ºä¾‹:
  python evaluator.py --mode single_sequential --scenario 00001
  python evaluator.py --mode single_independent --scenario 00001
  python evaluator.py --mode multi_combined --scenario 00002 --config my_config.yaml
  python evaluator.py --list-modes
        """
    )
    
    parser.add_argument(
        '--mode', '-m',
        choices=['single_sequential', 'single_combined', 'single_independent',
                'multi_sequential', 'multi_combined', 'multi_independent', 'parallel'],
        help='è¯„æµ‹æ¨¡å¼'
    )
    
    parser.add_argument(
        '--scenario', '-s',
        type=str,
        help='åœºæ™¯ID (å¦‚: 00001)'
    )
    
    parser.add_argument(
        '--config', '-c',
        type=str,
        help='é…ç½®æ–‡ä»¶å (å¯é€‰ï¼Œé»˜è®¤æ ¹æ®æ¨¡å¼è‡ªåŠ¨é€‰æ‹©)'
    )

    parser.add_argument(
        '--suffix',
        type=str,
        help='è‡ªå®šä¹‰è¿è¡Œåç¼€'
    )
    
    parser.add_argument(
        '--log-level',
        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
        default='INFO',
        help='æ—¥å¿—çº§åˆ« (é»˜è®¤: INFO)'
    )
    
    parser.add_argument(
        '--list-modes',
        action='store_true',
        help='åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„è¯„æµ‹æ¨¡å¼'
    )
    
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='å¹²è¿è¡Œæ¨¡å¼ï¼Œåªæ£€æŸ¥é…ç½®ä¸æ‰§è¡Œè¯„æµ‹'
    )
    
    return parser.parse_args()


def list_evaluation_modes():
    """åˆ—å‡ºæ‰€æœ‰è¯„æµ‹æ¨¡å¼"""
    modes = {
        'single_sequential': 'å•æ™ºèƒ½ä½“é€ä¸ªè¯„æµ‹ - åªåŠ è½½agent1ï¼Œæ¯ä¸ªå­ä»»åŠ¡ç‹¬ç«‹æ‰§è¡Œï¼Œä»»åŠ¡é—´æ¸…ç©ºå†å²',
        'single_combined': 'å•æ™ºèƒ½ä½“æ··åˆè¯„æµ‹ - åªåŠ è½½agent1ï¼Œå°†æ‰€æœ‰å­ä»»åŠ¡æ‹¼æ¥æˆä¸€ä¸ªé•¿ä»»åŠ¡æ‰§è¡Œ',
        'single_independent': 'å•æ™ºèƒ½ä½“ç‹¬ç«‹è¯„æµ‹ - åªåŠ è½½agent1ï¼Œæ¯ä¸ªå­ä»»åŠ¡åœ¨å…¨æ–°ç¯å¢ƒä¸­ç‹¬ç«‹æ‰§è¡Œ',
        'multi_sequential': 'å¤šæ™ºèƒ½ä½“é€ä¸ªè¯„æµ‹ - åŠ è½½æ‰€æœ‰æ™ºèƒ½ä½“ï¼Œæ¯ä¸ªå­ä»»åŠ¡ç‹¬ç«‹æ‰§è¡Œï¼Œä»»åŠ¡é—´æ¸…ç©ºå†å²',
        'multi_combined': 'å¤šæ™ºèƒ½ä½“æ··åˆè¯„æµ‹ - åŠ è½½æ‰€æœ‰æ™ºèƒ½ä½“ï¼Œå°†æ‰€æœ‰å­ä»»åŠ¡æ‹¼æ¥æˆä¸€ä¸ªé•¿ä»»åŠ¡æ‰§è¡Œ',
        'multi_independent': 'å¤šæ™ºèƒ½ä½“ç‹¬ç«‹è¯„æµ‹ - åŠ è½½æ‰€æœ‰æ™ºèƒ½ä½“ï¼Œæ¯ä¸ªå­ä»»åŠ¡åœ¨å…¨æ–°ç¯å¢ƒä¸­ç‹¬ç«‹æ‰§è¡Œ',
        'parallel': 'å¹¶è¡Œä»»åŠ¡è¯„æµ‹ - å¤šä¸ªä»»åŠ¡åŒæ—¶å¹¶è¡Œæ‰§è¡Œï¼Œæ¯ä¸ªä»»åŠ¡ä½¿ç”¨ç‹¬ç«‹çš„æ¨¡æ‹Ÿå™¨å®ä¾‹'
    }

    print("ğŸ“‹ å¯ç”¨çš„è¯„æµ‹æ¨¡å¼:")
    print("=" * 80)
    for mode, description in modes.items():
        print(f"  {mode:<20} - {description}")
    print("=" * 80)


def parse_mode(mode: str) -> tuple:
    """è§£æè¯„æµ‹æ¨¡å¼"""
    # å¹¶è¡Œæ¨¡å¼
    if mode == 'parallel':
        return 'single', 'sequential', 'single_agent_config', True

    # å¸¸è§„æ¨¡å¼
    if mode.startswith('single_'):
        agent_type = 'single'
        task_type = mode.replace('single_', '')
        config_file = 'single_agent_config'
    elif mode.startswith('multi_'):
        agent_type = 'multi'
        task_type = mode.replace('multi_', '')
        config_file = 'centralized_config'  # é»˜è®¤ä½¿ç”¨ä¸­å¿ƒåŒ–é…ç½®
    else:
        raise ValueError(f"æ— æ•ˆçš„è¯„æµ‹æ¨¡å¼: {mode}")

    return agent_type, task_type, config_file, False


def validate_config(config: dict, agent_type: str, task_type: str) -> bool:
    """éªŒè¯é…ç½®çš„æœ‰æ•ˆæ€§"""
    try:
        # æ£€æŸ¥å¿…è¦çš„é…ç½®é¡¹
        required_keys = ['evaluation']

        for key in required_keys:
            if key not in config:
                print(f"âŒ é…ç½®æ–‡ä»¶ç¼ºå°‘å¿…è¦é¡¹: {key}")
                return False

        # æ£€æŸ¥è¯„æµ‹é…ç½®
        eval_config = config['evaluation']
        if 'output' not in eval_config:
            print("âš ï¸ é…ç½®æ–‡ä»¶ç¼ºå°‘è¾“å‡ºé…ç½®ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼")

        print(f"âœ… é…ç½®éªŒè¯é€šè¿‡ - æ¨¡å¼: {agent_type}_{task_type}")
        return True

    except Exception as e:
        print(f"âŒ é…ç½®éªŒè¯å¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    args = parse_arguments()
    
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(
        level=getattr(logging, args.log_level),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    logger = logging.getLogger(__name__)
    
    # åˆ—å‡ºæ¨¡å¼
    if args.list_modes:
        list_evaluation_modes()
        return 0
    
    # æ£€æŸ¥å¿…è¦å‚æ•°
    if not args.mode:
        print("âŒ è¯·æŒ‡å®šè¯„æµ‹æ¨¡å¼ï¼Œä½¿ç”¨ --list-modes æŸ¥çœ‹å¯ç”¨æ¨¡å¼")
        return 1
    
    try:
        # è§£ææ¨¡å¼
        parse_result = parse_mode(args.mode)
        if len(parse_result) == 4:
            agent_type, task_type, default_config, is_parallel = parse_result
        else:
            agent_type, task_type, default_config = parse_result
            is_parallel = False

        # ç¡®å®šé…ç½®æ–‡ä»¶
        config_file = args.config or default_config

        # åŠ è½½é…ç½®
        config_manager = ConfigManager()
        config = config_manager.get_config(config_file)

        # éªŒè¯é…ç½®
        if not validate_config(config, agent_type, task_type):
            return 1

        # å¹²è¿è¡Œæ¨¡å¼
        if args.dry_run:
            mode_desc = "å¹¶è¡Œè¯„æµ‹" if is_parallel else f"{agent_type}_{task_type}"
            print(f"âœ… å¹²è¿è¡Œå®Œæˆ - é…ç½®æœ‰æ•ˆï¼Œæ¨¡å¼: {mode_desc}")
            print(f"ğŸ“‹ é…ç½®æ–‡ä»¶: {config_file}")
            print(f"ğŸ¯ åœºæ™¯: {args.scenario or 'default'}")
            return 0

        # åˆ›å»ºè¯„æµ‹å™¨
        logger.info(f"ğŸš€ å¯åŠ¨ä»»åŠ¡è¯„æµ‹å™¨ - æ¨¡å¼: {args.mode}")

        if is_parallel:
            # å¹¶è¡Œè¯„æµ‹æ¨¡å¼
            evaluator = ParallelTaskEvaluator(
                config_file=config_file,
                agent_type=agent_type,
                task_type=task_type,
                scenario_id=args.scenario,
                custom_suffix=args.suffix
            )
            # è¿è¡Œå¹¶è¡Œè¯„æµ‹
            results = evaluator.run_parallel_evaluation()
        else:
            # å¸¸è§„è¯„æµ‹æ¨¡å¼
            evaluator = TaskEvaluator(
                config_file=config_file,
                agent_type=agent_type,
                task_type=task_type,
                scenario_id=args.scenario,
                custom_suffix=args.suffix
            )
            # è¿è¡Œè¯„æµ‹
            results = evaluator.run_evaluation(args.scenario)

        # æ˜¾ç¤ºç»“æœæ‘˜è¦
        summary = results['summary']
        print(f"\nğŸ‰ è¯„æµ‹å®Œæˆ!")
        print(f"ğŸƒ è¿è¡Œåç§°: {results['run_name']}")
        print(f"ğŸ“Š å®Œæˆç‡: {summary['completion_rate']:.1%} ({summary['completed_tasks']}/{summary['total_tasks']})")
        print(f"ğŸ“Š æ€»æ­¥æ•°: {summary['total_steps']}")
        print(f"ğŸ“Š è€—æ—¶: {results['total_duration']:.2f}ç§’")
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶:")
        print(f"   è½¨è¿¹: {results['output_files']['trajectory_file']}")
        print(f"   æ—¥å¿—: {results['output_files']['log_file']}")

        if 'error' in results:
            print(f"âŒ è¯„æµ‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {results['error']}")
            return 1

        return 0
        
    except KeyboardInterrupt:
        logger.info("ğŸ›‘ ç”¨æˆ·ä¸­æ–­è¯„æµ‹")
        return 1
    except Exception as e:
        logger.exception(f"âŒ è¯„æµ‹å™¨è¿è¡Œå¤±è´¥: {e}")
        return 1


if __name__ == "__main__":
    sys.exit(main())
