#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šçº¿ç¨‹åŠŸèƒ½æµ‹è¯•è„šæœ¬

æµ‹è¯•é¡¹ç›®ä¸­çš„å„ç§å¤šçº¿ç¨‹åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
1. ThreadPoolManager çš„åŸºæœ¬åŠŸèƒ½
2. æ•°æ®ç”Ÿæˆå™¨çš„å¤šçº¿ç¨‹å¤„ç†
3. å¹¶è¡Œåœºæ™¯æ‰§è¡Œ
4. ç‹¬ç«‹ä»»åŠ¡æ‰§è¡Œå™¨çš„å¤šçº¿ç¨‹åŠŸèƒ½
5. æ¨¡æ‹Ÿå™¨çš„å¤šæ™ºèƒ½ä½“å¹¶å‘å¤„ç†
"""

import os
import sys
import time
import threading
import logging
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
from typing import List, Dict, Any
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.append(project_root)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def test_thread_pool_manager():
    """æµ‹è¯• ThreadPoolManager åŸºæœ¬åŠŸèƒ½"""
    logger.info("ğŸ§µ æµ‹è¯• ThreadPoolManager åŸºæœ¬åŠŸèƒ½")
    
    try:
        from data_generation.utils.thread_pool import ThreadPoolManager, TaskStatus
        
        def sample_task(item, thread_id):
            """ç¤ºä¾‹ä»»åŠ¡å‡½æ•°"""
            task_name = item.get('name', f'task_{thread_id}')
            sleep_time = item.get('sleep_time', 1)
            
            logger.info(f"  çº¿ç¨‹ {thread_id}: å¼€å§‹æ‰§è¡Œä»»åŠ¡ {task_name}")
            time.sleep(sleep_time)
            logger.info(f"  çº¿ç¨‹ {thread_id}: å®Œæˆä»»åŠ¡ {task_name}")
            
            return f"Task {task_name} completed by thread {thread_id}"
        
        # åˆ›å»ºæµ‹è¯•ä»»åŠ¡
        test_tasks = [
            {'name': f'task_{i}', 'sleep_time': 0.5} 
            for i in range(8)
        ]
        
        # åˆ›å»ºçº¿ç¨‹æ± ç®¡ç†å™¨
        pool_manager = ThreadPoolManager(num_threads=4, max_retries=2)
        
        # æ‰§è¡Œä»»åŠ¡
        start_time = time.time()
        results = pool_manager.execute_tasks(
            tasks=test_tasks,
            task_func=sample_task,
            task_id_func=lambda item: item['name']
        )
        end_time = time.time()
        
        # åˆ†æç»“æœ
        completed_count = sum(1 for r in results if r.status == TaskStatus.COMPLETED)
        failed_count = sum(1 for r in results if r.status == TaskStatus.FAILED)
        
        logger.info(f"  âœ… ThreadPoolManager æµ‹è¯•å®Œæˆ:")
        logger.info(f"     - æ€»ä»»åŠ¡æ•°: {len(test_tasks)}")
        logger.info(f"     - æˆåŠŸä»»åŠ¡: {completed_count}")
        logger.info(f"     - å¤±è´¥ä»»åŠ¡: {failed_count}")
        logger.info(f"     - æ€»è€—æ—¶: {end_time - start_time:.2f}s")
        logger.info(f"     - ç»Ÿè®¡ä¿¡æ¯: {pool_manager.get_statistics()}")
        
        return True
        
    except Exception as e:
        logger.error(f"  âŒ ThreadPoolManager æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_data_generator_threading():
    """æµ‹è¯•æ•°æ®ç”Ÿæˆå™¨çš„å¤šçº¿ç¨‹åŠŸèƒ½"""
    logger.info("ğŸ­ æµ‹è¯•æ•°æ®ç”Ÿæˆå™¨å¤šçº¿ç¨‹åŠŸèƒ½")
    
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®ç”Ÿæˆå™¨é…ç½®
        config_path = "data_generation/config"
        if not os.path.exists(config_path):
            logger.warning("  âš ï¸ æ•°æ®ç”Ÿæˆå™¨é…ç½®ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡æµ‹è¯•")
            return True
            
        # è¿™é‡Œå¯ä»¥æ·»åŠ å…·ä½“çš„æ•°æ®ç”Ÿæˆå™¨æµ‹è¯•
        logger.info("  âœ… æ•°æ®ç”Ÿæˆå™¨å¤šçº¿ç¨‹æµ‹è¯•é€šè¿‡ï¼ˆæ¨¡æ‹Ÿï¼‰")
        return True
        
    except Exception as e:
        logger.error(f"  âŒ æ•°æ®ç”Ÿæˆå™¨å¤šçº¿ç¨‹æµ‹è¯•å¤±è´¥: {e}")
        return False

def cpu_bound_task(n):
    """CPUå¯†é›†å‹ä»»åŠ¡ - å®šä¹‰åœ¨æ¨¡å—çº§åˆ«ä»¥æ”¯æŒpickle"""
    result = sum(i * i for i in range(n))
    return f"Task {n}: {result}"

def io_bound_task(delay):
    """IOå¯†é›†å‹ä»»åŠ¡ - å®šä¹‰åœ¨æ¨¡å—çº§åˆ«ä»¥æ”¯æŒpickle"""
    time.sleep(delay)
    return f"IO task completed after {delay}s"

def test_concurrent_futures():
    """æµ‹è¯• concurrent.futures çš„åŸºæœ¬åŠŸèƒ½"""
    logger.info("âš¡ æµ‹è¯• concurrent.futures åŸºæœ¬åŠŸèƒ½")
    
    try:
        # æµ‹è¯• ThreadPoolExecutor
        logger.info("  æµ‹è¯• ThreadPoolExecutor (IOå¯†é›†å‹)")
        with ThreadPoolExecutor(max_workers=4) as executor:
            io_tasks = [0.2, 0.3, 0.1, 0.4, 0.2]
            start_time = time.time()
            
            futures = [executor.submit(io_bound_task, delay) for delay in io_tasks]
            results = [future.result() for future in as_completed(futures)]
            
            end_time = time.time()
            logger.info(f"    - IOä»»åŠ¡å®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f}s")
            logger.info(f"    - ç»“æœæ•°é‡: {len(results)}")
        
        # æµ‹è¯• ProcessPoolExecutor
        logger.info("  æµ‹è¯• ProcessPoolExecutor (CPUå¯†é›†å‹)")
        with ProcessPoolExecutor(max_workers=2) as executor:
            cpu_tasks = [10000, 15000, 12000, 8000]
            start_time = time.time()
            
            futures = [executor.submit(cpu_bound_task, n) for n in cpu_tasks]
            results = [future.result() for future in as_completed(futures)]
            
            end_time = time.time()
            logger.info(f"    - CPUä»»åŠ¡å®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f}s")
            logger.info(f"    - ç»“æœæ•°é‡: {len(results)}")
        
        logger.info("  âœ… concurrent.futures æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        logger.error(f"  âŒ concurrent.futures æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_threading_primitives():
    """æµ‹è¯•çº¿ç¨‹åŒæ­¥åŸè¯­"""
    logger.info("ğŸ”’ æµ‹è¯•çº¿ç¨‹åŒæ­¥åŸè¯­")
    
    try:
        # æµ‹è¯• Lock
        shared_counter = 0
        counter_lock = threading.Lock()
        
        def increment_counter():
            nonlocal shared_counter
            for _ in range(1000):
                with counter_lock:
                    shared_counter += 1
        
        threads = []
        for _ in range(5):
            thread = threading.Thread(target=increment_counter)
            threads.append(thread)
            thread.start()
        
        for thread in threads:
            thread.join()
        
        logger.info(f"  Lockæµ‹è¯•: æœŸæœ›å€¼=5000, å®é™…å€¼={shared_counter}")
        
        # æµ‹è¯• Event
        event = threading.Event()
        results = []
        
        def wait_for_event(worker_id):
            logger.info(f"    å·¥ä½œçº¿ç¨‹ {worker_id} ç­‰å¾…äº‹ä»¶...")
            event.wait()
            results.append(f"Worker {worker_id} completed")
            logger.info(f"    å·¥ä½œçº¿ç¨‹ {worker_id} å®Œæˆ")
        
        # å¯åŠ¨ç­‰å¾…çº¿ç¨‹
        wait_threads = []
        for i in range(3):
            thread = threading.Thread(target=wait_for_event, args=(i,))
            wait_threads.append(thread)
            thread.start()
        
        time.sleep(0.5)  # è®©çº¿ç¨‹å¼€å§‹ç­‰å¾…
        logger.info("  è§¦å‘äº‹ä»¶...")
        event.set()  # è§¦å‘äº‹ä»¶
        
        for thread in wait_threads:
            thread.join()
        
        logger.info(f"  Eventæµ‹è¯•: å®Œæˆçš„å·¥ä½œçº¿ç¨‹æ•°={len(results)}")
        logger.info("  âœ… çº¿ç¨‹åŒæ­¥åŸè¯­æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        logger.error(f"  âŒ çº¿ç¨‹åŒæ­¥åŸè¯­æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_simulator_multithreading():
    """æµ‹è¯•æ¨¡æ‹Ÿå™¨çš„å¤šçº¿ç¨‹åŠŸèƒ½"""
    logger.info("ğŸ¤– æµ‹è¯•æ¨¡æ‹Ÿå™¨å¤šçº¿ç¨‹åŠŸèƒ½")
    
    try:
        # æ£€æŸ¥æ¨¡æ‹Ÿå™¨æ˜¯å¦å­˜åœ¨
        simulator_path = "utils/embodied_simulator"
        if not os.path.exists(simulator_path):
            logger.warning("  âš ï¸ æ¨¡æ‹Ÿå™¨ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡æµ‹è¯•")
            return True
        
        # æ£€æŸ¥æµ‹è¯•æ–‡ä»¶
        test_files = [
            "utils/embodied_simulator/tests/test_proximity_and_cooperation.py",
            "utils/embodied_simulator/tests/test_scenario_001_tasks.py"
        ]
        
        available_tests = [f for f in test_files if os.path.exists(f)]
        
        if not available_tests:
            logger.warning("  âš ï¸ æ¨¡æ‹Ÿå™¨æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡æµ‹è¯•")
            return True
        
        logger.info(f"  æ‰¾åˆ° {len(available_tests)} ä¸ªæ¨¡æ‹Ÿå™¨æµ‹è¯•æ–‡ä»¶")
        logger.info("  âœ… æ¨¡æ‹Ÿå™¨å¤šçº¿ç¨‹æµ‹è¯•é€šè¿‡ï¼ˆæ£€æŸ¥ï¼‰")
        return True
        
    except Exception as e:
        logger.error(f"  âŒ æ¨¡æ‹Ÿå™¨å¤šçº¿ç¨‹æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹å¤šçº¿ç¨‹åŠŸèƒ½æµ‹è¯•")
    logger.info("=" * 60)
    
    test_results = {}
    
    # è¿è¡Œå„é¡¹æµ‹è¯•
    tests = [
        ("ThreadPoolManager", test_thread_pool_manager),
        ("æ•°æ®ç”Ÿæˆå™¨å¤šçº¿ç¨‹", test_data_generator_threading),
        ("concurrent.futures", test_concurrent_futures),
        ("çº¿ç¨‹åŒæ­¥åŸè¯­", test_threading_primitives),
        ("æ¨¡æ‹Ÿå™¨å¤šçº¿ç¨‹", test_simulator_multithreading),
    ]
    
    for test_name, test_func in tests:
        logger.info(f"\nğŸ“‹ è¿è¡Œæµ‹è¯•: {test_name}")
        logger.info("-" * 40)
        
        try:
            result = test_func()
            test_results[test_name] = result
            status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
            logger.info(f"æµ‹è¯• {test_name}: {status}")
        except Exception as e:
            test_results[test_name] = False
            logger.error(f"æµ‹è¯• {test_name} å¼‚å¸¸: {e}")
    
    # è¾“å‡ºæ€»ç»“
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ¯ æµ‹è¯•æ€»ç»“")
    logger.info("=" * 60)
    
    passed_count = sum(1 for result in test_results.values() if result)
    total_count = len(test_results)
    
    for test_name, result in test_results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        logger.info(f"  {test_name}: {status}")
    
    logger.info(f"\næ€»è®¡: {passed_count}/{total_count} æµ‹è¯•é€šè¿‡")
    
    if passed_count == total_count:
        logger.info("ğŸ‰ æ‰€æœ‰å¤šçº¿ç¨‹æµ‹è¯•é€šè¿‡ï¼")
        return 0
    else:
        logger.warning(f"âš ï¸ {total_count - passed_count} ä¸ªæµ‹è¯•å¤±è´¥")
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
