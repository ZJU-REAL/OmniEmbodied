#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é¡¹ç›®å¤šçº¿ç¨‹åŠŸèƒ½æ·±åº¦æµ‹è¯•è„šæœ¬

ä¸“é—¨æµ‹è¯•OmniEmbodiedé¡¹ç›®ä¸­çš„å®é™…å¤šçº¿ç¨‹ä½¿ç”¨åœºæ™¯ï¼š
1. å¹¶è¡Œåœºæ™¯æ‰§è¡Œï¼ˆcentralized_example.pyä¸­çš„ProcessPoolExecutorï¼‰
2. æ•°æ®ç”Ÿæˆå™¨çš„å¤šçº¿ç¨‹å¤„ç†
3. ç‹¬ç«‹ä»»åŠ¡æ‰§è¡Œå™¨çš„çº¿ç¨‹å®‰å…¨æ€§
4. æ¨¡æ‹Ÿå™¨çš„å¤šæ™ºèƒ½ä½“å¹¶å‘å¤„ç†
"""

import os
import sys
import time
import logging
import json
from concurrent.futures import ProcessPoolExecutor, as_completed
from typing import List, Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.append(project_root)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def mock_execute_single_scenario(scenario_data):
    """æ¨¡æ‹Ÿå•ä¸ªåœºæ™¯æ‰§è¡Œ - å®šä¹‰åœ¨æ¨¡å—çº§åˆ«ä»¥æ”¯æŒpickle"""
    scenario_id = scenario_data['id']
    execution_time = scenario_data.get('execution_time', 1.0)

    # ä½¿ç”¨printè€Œä¸æ˜¯loggerï¼Œå› ä¸ºåœ¨å­è¿›ç¨‹ä¸­loggerå¯èƒ½ä¸å¯ç”¨
    print(f"    å¼€å§‹æ‰§è¡Œåœºæ™¯ {scenario_id}")
    time.sleep(execution_time)  # æ¨¡æ‹Ÿæ‰§è¡Œæ—¶é—´

    result = {
        'scenario_id': scenario_id,
        'status': 'success',
        'execution_time': execution_time,
        'message': f'åœºæ™¯ {scenario_id} æ‰§è¡Œå®Œæˆ'
    }

    print(f"    åœºæ™¯ {scenario_id} æ‰§è¡Œå®Œæˆ")
    return result

def test_parallel_scenario_execution():
    """æµ‹è¯•å¹¶è¡Œåœºæ™¯æ‰§è¡ŒåŠŸèƒ½"""
    logger.info("ğŸ¬ æµ‹è¯•å¹¶è¡Œåœºæ™¯æ‰§è¡ŒåŠŸèƒ½")

    try:
        # æ£€æŸ¥centralized_example.pyæ˜¯å¦å­˜åœ¨
        example_file = "examples/centralized_example.py"
        if not os.path.exists(example_file):
            logger.warning("  âš ï¸ centralized_example.py ä¸å­˜åœ¨ï¼Œè·³è¿‡æµ‹è¯•")
            return True
        
        # åˆ›å»ºæµ‹è¯•åœºæ™¯
        test_scenarios = [
            {'id': 'scenario_001', 'execution_time': 0.5},
            {'id': 'scenario_002', 'execution_time': 0.3},
            {'id': 'scenario_003', 'execution_time': 0.7},
            {'id': 'scenario_004', 'execution_time': 0.4},
        ]
        
        logger.info(f"  å‡†å¤‡å¹¶è¡Œæ‰§è¡Œ {len(test_scenarios)} ä¸ªåœºæ™¯")
        
        # ä½¿ç”¨ProcessPoolExecutorå¹¶è¡Œæ‰§è¡Œ
        start_time = time.time()
        results = []
        
        with ProcessPoolExecutor(max_workers=2) as executor:
            # æäº¤æ‰€æœ‰åœºæ™¯ä»»åŠ¡
            future_to_scenario = {
                executor.submit(mock_execute_single_scenario, scenario): scenario['id']
                for scenario in test_scenarios
            }
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_scenario):
                scenario_id = future_to_scenario[future]
                try:
                    result = future.result()
                    results.append(result)
                except Exception as e:
                    logger.error(f"    åœºæ™¯ {scenario_id} æ‰§è¡Œå¤±è´¥: {e}")
                    results.append({
                        'scenario_id': scenario_id,
                        'status': 'failed',
                        'error': str(e)
                    })
        
        end_time = time.time()
        
        # åˆ†æç»“æœ
        successful_count = sum(1 for r in results if r['status'] == 'success')
        total_execution_time = end_time - start_time
        
        logger.info(f"  âœ… å¹¶è¡Œåœºæ™¯æ‰§è¡Œæµ‹è¯•å®Œæˆ:")
        logger.info(f"     - æ€»åœºæ™¯æ•°: {len(test_scenarios)}")
        logger.info(f"     - æˆåŠŸåœºæ™¯: {successful_count}")
        logger.info(f"     - æ€»è€—æ—¶: {total_execution_time:.2f}s")
        logger.info(f"     - ç†è®ºä¸²è¡Œè€—æ—¶: {sum(s['execution_time'] for s in test_scenarios):.2f}s")
        
        return successful_count == len(test_scenarios)
        
    except Exception as e:
        logger.error(f"  âŒ å¹¶è¡Œåœºæ™¯æ‰§è¡Œæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_data_generation_threading():
    """æµ‹è¯•æ•°æ®ç”Ÿæˆå™¨çš„å®é™…å¤šçº¿ç¨‹åŠŸèƒ½"""
    logger.info("ğŸ­ æµ‹è¯•æ•°æ®ç”Ÿæˆå™¨å®é™…å¤šçº¿ç¨‹åŠŸèƒ½")
    
    try:
        # æ£€æŸ¥æ•°æ®ç”Ÿæˆå™¨æ˜¯å¦å¯ç”¨
        try:
            from data_generation.utils.thread_pool import ThreadPoolManager
            from data_generation.generators.base_generator import BaseGenerator
        except ImportError as e:
            logger.warning(f"  âš ï¸ æ— æ³•å¯¼å…¥æ•°æ®ç”Ÿæˆå™¨æ¨¡å—: {e}")
            return True
        
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•ç”Ÿæˆå™¨
        class TestGenerator(BaseGenerator):
            def __init__(self):
                # æ¨¡æ‹Ÿé…ç½®
                config = {
                    'thread_num': 3,
                    'max_retries': 2,
                    'retry_delay': 0.1
                }
                super().__init__(config)
            
            def _generate_single(self, item, thread_id):
                """ç”Ÿæˆå•ä¸ªæ•°æ®é¡¹"""
                item_id = item.get('id', 'unknown')
                processing_time = item.get('processing_time', 0.2)
                
                logger.info(f"    çº¿ç¨‹ {thread_id}: å¤„ç†æ•°æ®é¡¹ {item_id}")
                time.sleep(processing_time)
                
                # æ¨¡æ‹Ÿç”Ÿæˆç»“æœ
                result = {
                    'item_id': item_id,
                    'generated_data': f'Generated data for {item_id}',
                    'thread_id': thread_id,
                    'processing_time': processing_time
                }
                
                logger.info(f"    çº¿ç¨‹ {thread_id}: å®Œæˆæ•°æ®é¡¹ {item_id}")
                return result
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_items = [
            {'id': f'item_{i}', 'processing_time': 0.1 + (i % 3) * 0.1}
            for i in range(6)
        ]
        
        # æ‰§è¡Œæ‰¹é‡ç”Ÿæˆ
        generator = TestGenerator()
        start_time = time.time()
        results = generator.generate_batch(test_items, num_threads=3)
        end_time = time.time()
        
        # åˆ†æç»“æœ
        successful_results = [r for r in results if r.status.value == 'completed']
        
        logger.info(f"  âœ… æ•°æ®ç”Ÿæˆå™¨å¤šçº¿ç¨‹æµ‹è¯•å®Œæˆ:")
        logger.info(f"     - æ€»æ•°æ®é¡¹: {len(test_items)}")
        logger.info(f"     - æˆåŠŸç”Ÿæˆ: {len(successful_results)}")
        logger.info(f"     - æ€»è€—æ—¶: {end_time - start_time:.2f}s")
        
        return len(successful_results) == len(test_items)
        
    except Exception as e:
        logger.error(f"  âŒ æ•°æ®ç”Ÿæˆå™¨å¤šçº¿ç¨‹æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_independent_task_executor():
    """æµ‹è¯•ç‹¬ç«‹ä»»åŠ¡æ‰§è¡Œå™¨çš„çº¿ç¨‹å®‰å…¨æ€§"""
    logger.info("ğŸ”„ æµ‹è¯•ç‹¬ç«‹ä»»åŠ¡æ‰§è¡Œå™¨çº¿ç¨‹å®‰å…¨æ€§")
    
    try:
        # æ£€æŸ¥ç‹¬ç«‹ä»»åŠ¡æ‰§è¡Œå™¨æ˜¯å¦å¯ç”¨
        executor_file = "utils/independent_task_executor.py"
        if not os.path.exists(executor_file):
            logger.warning("  âš ï¸ ç‹¬ç«‹ä»»åŠ¡æ‰§è¡Œå™¨æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡æµ‹è¯•")
            return True
        
        try:
            from utils.independent_task_executor import IndependentTaskExecutor
        except ImportError as e:
            logger.warning(f"  âš ï¸ æ— æ³•å¯¼å…¥ç‹¬ç«‹ä»»åŠ¡æ‰§è¡Œå™¨: {e}")
            return True
        
        # è¿™é‡Œä¸»è¦æµ‹è¯•çº¿ç¨‹å®‰å…¨çš„æ•°æ®ç»“æ„å’Œæ“ä½œ
        logger.info("  æµ‹è¯•ç‹¬ç«‹ä»»åŠ¡æ‰§è¡Œå™¨çš„çº¿ç¨‹å®‰å…¨æ“ä½œ...")
        
        # æ¨¡æ‹Ÿå¤šä¸ªä»»åŠ¡æ‰§è¡Œå™¨å®ä¾‹çš„å¹¶å‘åˆ›å»ºå’Œé”€æ¯
        import threading
        
        results = []
        results_lock = threading.Lock()
        
        def create_and_test_executor(executor_id):
            """åˆ›å»ºå’Œæµ‹è¯•æ‰§è¡Œå™¨å®ä¾‹"""
            try:
                # æ¨¡æ‹Ÿåˆ›å»ºæ‰§è¡Œå™¨ï¼ˆä¸å®é™…è¿è¡Œï¼Œåªæµ‹è¯•å®ä¾‹åŒ–ï¼‰
                logger.info(f"    åˆ›å»ºæ‰§è¡Œå™¨å®ä¾‹ {executor_id}")
                time.sleep(0.1)  # æ¨¡æ‹Ÿåˆå§‹åŒ–æ—¶é—´
                
                with results_lock:
                    results.append(f"executor_{executor_id}_success")
                    
                logger.info(f"    æ‰§è¡Œå™¨å®ä¾‹ {executor_id} åˆ›å»ºæˆåŠŸ")
                
            except Exception as e:
                logger.error(f"    æ‰§è¡Œå™¨å®ä¾‹ {executor_id} åˆ›å»ºå¤±è´¥: {e}")
                with results_lock:
                    results.append(f"executor_{executor_id}_failed")
        
        # å¹¶å‘åˆ›å»ºå¤šä¸ªæ‰§è¡Œå™¨å®ä¾‹
        threads = []
        for i in range(4):
            thread = threading.Thread(target=create_and_test_executor, args=(i,))
            threads.append(thread)
            thread.start()
        
        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for thread in threads:
            thread.join()
        
        successful_count = sum(1 for r in results if 'success' in r)
        
        logger.info(f"  âœ… ç‹¬ç«‹ä»»åŠ¡æ‰§è¡Œå™¨çº¿ç¨‹å®‰å…¨æµ‹è¯•å®Œæˆ:")
        logger.info(f"     - æ€»æ‰§è¡Œå™¨å®ä¾‹: 4")
        logger.info(f"     - æˆåŠŸåˆ›å»º: {successful_count}")
        
        return successful_count == 4
        
    except Exception as e:
        logger.error(f"  âŒ ç‹¬ç«‹ä»»åŠ¡æ‰§è¡Œå™¨æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_simulator_concurrent_agents():
    """æµ‹è¯•æ¨¡æ‹Ÿå™¨çš„å¤šæ™ºèƒ½ä½“å¹¶å‘å¤„ç†"""
    logger.info("ğŸ¤– æµ‹è¯•æ¨¡æ‹Ÿå™¨å¤šæ™ºèƒ½ä½“å¹¶å‘å¤„ç†")
    
    try:
        # æ£€æŸ¥æ¨¡æ‹Ÿå™¨æµ‹è¯•æ–‡ä»¶
        test_files = [
            "utils/embodied_simulator/tests/test_proximity_and_cooperation.py",
            "utils/embodied_simulator/tests/test_scenario_001_tasks.py"
        ]
        
        available_tests = [f for f in test_files if os.path.exists(f)]
        
        if not available_tests:
            logger.warning("  âš ï¸ æ¨¡æ‹Ÿå™¨æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡æµ‹è¯•")
            return True
        
        # æ¨¡æ‹Ÿå¤šæ™ºèƒ½ä½“å¹¶å‘æ“ä½œ
        import threading
        
        agent_results = {}
        results_lock = threading.Lock()
        
        def simulate_agent_action(agent_id):
            """æ¨¡æ‹Ÿæ™ºèƒ½ä½“åŠ¨ä½œ"""
            logger.info(f"    æ™ºèƒ½ä½“ {agent_id} å¼€å§‹æ‰§è¡ŒåŠ¨ä½œ")
            
            # æ¨¡æ‹Ÿæ™ºèƒ½ä½“æ€è€ƒå’Œæ‰§è¡Œæ—¶é—´
            think_time = 0.1 + (agent_id % 3) * 0.05
            time.sleep(think_time)
            
            # æ¨¡æ‹ŸåŠ¨ä½œæ‰§è¡Œ
            action_result = {
                'agent_id': agent_id,
                'action': f'move_to_location_{agent_id}',
                'status': 'completed',
                'execution_time': think_time
            }
            
            with results_lock:
                agent_results[agent_id] = action_result
            
            logger.info(f"    æ™ºèƒ½ä½“ {agent_id} å®ŒæˆåŠ¨ä½œ")
        
        # å¹¶å‘æ‰§è¡Œå¤šä¸ªæ™ºèƒ½ä½“
        agent_threads = []
        for agent_id in range(5):
            thread = threading.Thread(target=simulate_agent_action, args=(agent_id,))
            agent_threads.append(thread)
            thread.start()
        
        # ç­‰å¾…æ‰€æœ‰æ™ºèƒ½ä½“å®Œæˆ
        for thread in agent_threads:
            thread.join()
        
        successful_agents = sum(1 for result in agent_results.values() 
                              if result['status'] == 'completed')
        
        logger.info(f"  âœ… æ¨¡æ‹Ÿå™¨å¤šæ™ºèƒ½ä½“å¹¶å‘æµ‹è¯•å®Œæˆ:")
        logger.info(f"     - æ€»æ™ºèƒ½ä½“æ•°: 5")
        logger.info(f"     - æˆåŠŸæ‰§è¡Œ: {successful_agents}")
        logger.info(f"     - å¯ç”¨æµ‹è¯•æ–‡ä»¶: {len(available_tests)}")
        
        return successful_agents == 5
        
    except Exception as e:
        logger.error(f"  âŒ æ¨¡æ‹Ÿå™¨å¤šæ™ºèƒ½ä½“å¹¶å‘æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹é¡¹ç›®å¤šçº¿ç¨‹åŠŸèƒ½æ·±åº¦æµ‹è¯•")
    logger.info("=" * 60)
    
    test_results = {}
    
    # è¿è¡Œå„é¡¹æµ‹è¯•
    tests = [
        ("å¹¶è¡Œåœºæ™¯æ‰§è¡Œ", test_parallel_scenario_execution),
        ("æ•°æ®ç”Ÿæˆå™¨å¤šçº¿ç¨‹", test_data_generation_threading),
        ("ç‹¬ç«‹ä»»åŠ¡æ‰§è¡Œå™¨", test_independent_task_executor),
        ("æ¨¡æ‹Ÿå™¨å¤šæ™ºèƒ½ä½“å¹¶å‘", test_simulator_concurrent_agents),
    ]
    
    for test_name, test_func in tests:
        logger.info(f"\nğŸ“‹ è¿è¡Œæµ‹è¯•: {test_name}")
        logger.info("-" * 40)
        
        try:
            result = test_func()
            test_results[test_name] = result
            status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
            logger.info(f"æµ‹è¯• {test_name}: {status}")
        except Exception as e:
            test_results[test_name] = False
            logger.error(f"æµ‹è¯• {test_name} å¼‚å¸¸: {e}")
    
    # è¾“å‡ºæ€»ç»“
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ¯ é¡¹ç›®å¤šçº¿ç¨‹æµ‹è¯•æ€»ç»“")
    logger.info("=" * 60)
    
    passed_count = sum(1 for result in test_results.values() if result)
    total_count = len(test_results)
    
    for test_name, result in test_results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        logger.info(f"  {test_name}: {status}")
    
    logger.info(f"\næ€»è®¡: {passed_count}/{total_count} æµ‹è¯•é€šè¿‡")
    
    if passed_count == total_count:
        logger.info("ğŸ‰ æ‰€æœ‰é¡¹ç›®å¤šçº¿ç¨‹æµ‹è¯•é€šè¿‡ï¼")
        return 0
    else:
        logger.warning(f"âš ï¸ {total_count - passed_count} ä¸ªæµ‹è¯•å¤±è´¥")
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
