#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸­å¿ƒåŒ–å¤šæ™ºèƒ½ä½“ç¤ºä¾‹ - ä½¿ç”¨æ–°çš„è¯„æµ‹å™¨æ‰§è¡Œä»»åŠ¡

è¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨é‡æ„åçš„è¯„æµ‹å™¨æ¥æ‰§è¡Œä¸­å¿ƒåŒ–å¤šæ™ºèƒ½ä½“ä»»åŠ¡ã€‚
è¯„æµ‹å™¨æä¾›äº†å®Œæ•´çš„æ—¥å¿—è®°å½•ã€è½¨è¿¹è®°å½•å’Œè¯„æµ‹åŠŸèƒ½ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
1. ä»é…ç½®æ–‡ä»¶åŠ è½½å®Œæ•´é…ç½®
2. æ”¯æŒä¸åŒçš„è¯„æµ‹æ¨¡å¼é…ç½®
3. è‡ªåŠ¨è®°å½•æ‰§è¡Œè½¨è¿¹å’Œæ—¥å¿—
4. ç”Ÿæˆè¯¦ç»†çš„è¯„æµ‹æŠ¥å‘Š
5. æ”¯æŒå‘½ä»¤è¡Œå‚æ•°è¦†ç›–é…ç½®æ–‡ä»¶è®¾ç½®
6. ä¸­å¿ƒåŒ–åè°ƒä¸¤ä¸ªæ™ºèƒ½ä½“å®Œæˆä»»åŠ¡

ä½¿ç”¨æ–¹æ³•ï¼š
python examples/centralized_agent_example.py --mode sequential --scenarios 00001 --suffix demo
python examples/centralized_agent_example.py --mode combined --scenarios 00001-00003 --suffix test
python examples/centralized_agent_example.py --config centralized_config --parallel
"""

import sys
import os
import logging
import argparse

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

# å¯¼å…¥æ–°çš„è¯„æµ‹å™¨å’Œé…ç½®ç³»ç»Ÿ
from evaluation.evaluation_interface import EvaluationInterface
from config.config_manager import get_config_manager
from config.config_override import ConfigOverrideParser, create_config_aware_parser
from config.config_utils import print_config_summary


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = create_config_aware_parser(description='ä¸­å¿ƒåŒ–å¤šæ™ºèƒ½ä½“ä»»åŠ¡æ‰§è¡Œç¤ºä¾‹')
    parser.add_argument('--mode', type=str,
                        choices=['sequential', 'combined', 'independent'],
                        help='è¯„æµ‹æ¨¡å¼: sequential (é€ä¸ªè¯„æµ‹), combined (æ··åˆè¯„æµ‹), independent (ç‹¬ç«‹è¯„æµ‹)')
    parser.add_argument('--scenarios', type=str, default='00001',
                        help='åœºæ™¯é€‰æ‹©: all, 00001-00010, 00001,00003,00005')
    parser.add_argument('--suffix', type=str, default='demo',
                        help='è¿è¡Œåç¼€')
    parser.add_argument('--config', type=str, default='centralized_config',
                        help='é…ç½®æ–‡ä»¶å (é»˜è®¤: centralized_config)')
    parser.add_argument('--log-level', type=str,
                        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
                        default='INFO',
                        help='æ—¥å¿—çº§åˆ«')
    parser.add_argument('--parallel', action='store_true',
                        help='å¯ç”¨å¹¶è¡Œè¯„æµ‹æ¨¡å¼')
    parser.add_argument('--show-config', action='store_true',
                        help='æ˜¾ç¤ºæœ€ç»ˆé…ç½®å¹¶é€€å‡º')

    # ä¾¿æ·çš„æ¨¡å‹é€‰æ‹©å‚æ•°
    model_group = parser.add_argument_group('ä¾¿æ·æ¨¡å‹é€‰æ‹©')
    model_group.add_argument('--model', type=str,
                           choices=['deepseek', 'deepseekv3', 'deepseekr1', 'qwen06b', 'qwen3b', 'qwen7b', 'qwen72b','llama8b', 'openai', 'volcengine', 'bailian'],
                           help='å¿«é€Ÿé€‰æ‹©æ¨¡å‹: deepseek, deepseekv3, deepseekr1, qwen06b, qwen3b, qwen7b, qwen72b, llama8b, openai, volcengine, bailian')
    model_group.add_argument('--observation-mode', type=str,
                           choices=['explore', 'global'],
                           help='è§‚å¯Ÿæ¨¡å¼: explore (æ¢ç´¢æ¨¡å¼ï¼Œåªæ˜¾ç¤ºå·²å‘ç°ç‰©ä½“), global (å…¨å±€æ¨¡å¼ï¼Œæ˜¾ç¤ºæ‰€æœ‰ç‰©ä½“)')

    # æ³¨æ„ï¼šcreate_config_aware_parser å·²ç»æ·»åŠ äº†é…ç½®è¦†ç›–æ”¯æŒï¼Œæ— éœ€é‡å¤æ·»åŠ 

    return parser.parse_args()


def run_centralized_evaluation(config_file: str, mode: str, scenarios: str, suffix: str):
    """
    è¿è¡Œä¸­å¿ƒåŒ–å¤šæ™ºèƒ½ä½“è¯„æµ‹

    Args:
        config_file: é…ç½®æ–‡ä»¶å
        mode: è¯„æµ‹æ¨¡å¼
        scenarios: åœºæ™¯é€‰æ‹©å­—ç¬¦ä¸²
        suffix: è¿è¡Œåç¼€

    Returns:
        int: é€€å‡ºç 
    """
    logger = logging.getLogger(__name__)

    try:
        # åŠ è½½é…ç½®
        config_manager = get_config_manager()
        config = config_manager.get_config(config_file)

        # è·å–æ•°æ®é›†é…ç½®
        dataset_name = config.get('dataset', {}).get('default', 'eval_multi')

        # ä¸¥æ ¼éªŒè¯æ•°æ®ç›®å½•é…ç½® - ç›´æ¥æŠ›å‡ºå¼‚å¸¸
        data_dir = config_manager.get_data_dir(config_file, dataset_name)
        scene_dir = config_manager.get_scene_dir(config_file, dataset_name)
        task_dir = config_manager.get_task_dir(config_file, dataset_name)

        logger.info(f"ğŸ“ ä½¿ç”¨æ•°æ®é›†: {dataset_name}")
        logger.info(f"ğŸ“ æ•°æ®ç›®å½•: {data_dir}")
        logger.info(f"ğŸ“ åœºæ™¯ç›®å½•: {scene_dir}")
        logger.info(f"ğŸ“ ä»»åŠ¡ç›®å½•: {task_dir}")

        # è§£æåœºæ™¯é€‰æ‹©
        scenario_selection = EvaluationInterface.parse_scenario_string(scenarios)

        # è¿è¡Œè¯„æµ‹
        logger.info(f"ğŸš€ å¼€å§‹ä¸­å¿ƒåŒ–å¤šæ™ºèƒ½ä½“è¯„æµ‹")
        logger.info(f"ğŸ“‹ è¯„æµ‹æ¨¡å¼: {mode}")
        logger.info(f"ğŸ  åœºæ™¯é€‰æ‹©: {scenarios}")
        logger.info(f"ğŸ·ï¸ è¿è¡Œåç¼€: {suffix}")
        logger.info(f"âš™ï¸ é…ç½®æ–‡ä»¶: {config_file}")
        logger.info(f"ğŸ¤– æ™ºèƒ½ä½“ç±»å‹: ä¸­å¿ƒåŒ–å¤šæ™ºèƒ½ä½“ (2ä¸ªæ™ºèƒ½ä½“)")

        results = EvaluationInterface.run_evaluation(
            config_file=config_file,
            agent_type='multi',  # å¤šæ™ºèƒ½ä½“ç±»å‹
            task_type=mode,
            scenario_selection=scenario_selection,
            custom_suffix=suffix
        )

        # æ˜¾ç¤ºç»“æœ
        run_info = results.get('runinfo', {})  # ä¿®æ­£é”®å
        overall_summary = results.get('overall_summary', {})

        logger.info("\nğŸ‰ ä¸­å¿ƒåŒ–å¤šæ™ºèƒ½ä½“è¯„æµ‹å®Œæˆï¼")
        logger.info("ğŸ“Š è¯„æµ‹ç»“æœ:")
        logger.info(f"  - è¿è¡ŒID: {run_info.get('run_id', 'Unknown')}")  # ä¿®æ­£å­—æ®µå
        logger.info(f"  - æ€»è€—æ—¶: {run_info.get('duration_seconds', 0):.2f} ç§’")  # ä¿®æ­£å­—æ®µå
        logger.info(f"  - åœºæ™¯æ•°é‡: {run_info.get('total_scenarios', 0)}")  # ä»run_infoè·å–
        logger.info(f"  - ä»»åŠ¡æ€»æ•°: {overall_summary.get('total_tasks', 0)}")
        logger.info(f"  - å®Œæˆä»»åŠ¡: {overall_summary.get('total_completed_tasks', 0)}")
        logger.info(f"  - æ€»ä½“å®Œæˆç‡: {overall_summary.get('overall_completion_rate', 0):.2%}")
        logger.info(f"  - æ¨¡å‹å‡†ç¡®ç‡: {overall_summary.get('overall_completion_accuracy', 0):.2%}")
        logger.info(f"ğŸ“ ç»“æœä¿å­˜åœ¨: output/{run_info.get('run_id', 'unknown')}/")  # ä¿®æ­£å­—æ®µå

        # æ˜¾ç¤ºåä½œæ•ˆæœè¯„ä»·
        completion_rate = overall_summary.get('overall_completion_rate', 0)
        if completion_rate >= 0.8:
            logger.info("ğŸŠ ä¸­å¿ƒåŒ–åä½œæ•ˆæœä¼˜ç§€ï¼")
        elif completion_rate >= 0.6:
            logger.info("ğŸ‘ ä¸­å¿ƒåŒ–åä½œæ•ˆæœè‰¯å¥½ï¼")
        else:
            logger.info("ğŸ“ˆ åä½œç­–ç•¥è¿˜æœ‰æ”¹è¿›ç©ºé—´")

        return 0

    except Exception as e:
        logger.error(f"âŒ ä¸­å¿ƒåŒ–å¤šæ™ºèƒ½ä½“è¯„æµ‹å¤±è´¥: {e}")
        import traceback
        logger.error(f"é”™è¯¯è¯¦æƒ…:\n{traceback.format_exc()}")
        return 1


def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_args()

    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(
        level=getattr(logging, args.log_level),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    logger = logging.getLogger(__name__)

    # å¤„ç†ä¾¿æ·å‚æ•°ï¼Œè½¬æ¢ä¸ºé…ç½®è¦†ç›–
    if hasattr(args, 'model') and args.model:
        # å°†ä¾¿æ·æ¨¡å‹å‚æ•°è½¬æ¢ä¸ºé…ç½®è¦†ç›–
        if not hasattr(args, 'config_override') or args.config_override is None:
            args.config_override = []
        args.config_override.append(f'llm_config.api.provider={args.model}')
        logger.info(f"ğŸ¯ ä¾¿æ·æ¨¡å‹é€‰æ‹©: {args.model}")

    if hasattr(args, 'observation_mode') and args.observation_mode:
        # å°†è§‚å¯Ÿæ¨¡å¼å‚æ•°è½¬æ¢ä¸ºé…ç½®è¦†ç›–
        if not hasattr(args, 'config_override') or args.config_override is None:
            args.config_override = []

        only_show_discovered = 'true' if args.observation_mode == 'explore' else 'false'
        args.config_override.append(f'{args.config}.agent_config.environment_description.only_show_discovered={only_show_discovered}')
        logger.info(f"ğŸ‘ï¸ è§‚å¯Ÿæ¨¡å¼: {args.observation_mode} ({'æ¢ç´¢æ¨¡å¼' if args.observation_mode == 'explore' else 'å…¨å±€æ¨¡å¼'})")

    # åº”ç”¨é…ç½®è¦†ç›–
    ConfigOverrideParser.apply_config_overrides(args, args.config)

    # è·å–é…ç½®ç®¡ç†å™¨å¹¶æ˜¾ç¤ºæœ€ç»ˆé…ç½®
    config_manager = get_config_manager()
    config = config_manager.get_config(args.config)
    eval_config = config.get('evaluation', {})
    run_settings = eval_config.get('run_settings', {})
    parallel_settings = config.get('parallel_evaluation', {})

    # ç¡®å®šæœ€ç»ˆå‚æ•°ï¼ˆå‘½ä»¤è¡Œå‚æ•°ä¼˜å…ˆï¼Œç„¶åæ˜¯é…ç½®æ–‡ä»¶ï¼‰
    mode = args.mode or eval_config['task_type']

    # åœºæ™¯é€‰æ‹©é€»è¾‘ï¼šå¦‚æœå‘½ä»¤è¡Œæ²¡æœ‰æ˜ç¡®æŒ‡å®šï¼ˆä½¿ç”¨é»˜è®¤å€¼ï¼‰ï¼Œåˆ™å°è¯•ä½¿ç”¨é…ç½®æ–‡ä»¶
    if args.scenarios == '00001':  # é»˜è®¤å€¼ï¼Œæ£€æŸ¥é…ç½®æ–‡ä»¶
        scenario_selection = parallel_settings['scenario_selection']
        selection_mode = scenario_selection['mode']

        if selection_mode == 'all':
            scenarios = 'all'
        elif selection_mode == 'range':
            range_config = scenario_selection['range']
            start = range_config['start']
            end = range_config['end']
            scenarios = f"{start}-{end}" if start != end else start
        elif selection_mode == 'list':
            scenario_list = scenario_selection['list']
            scenarios = ','.join(scenario_list)
        else:
            raise ValueError(f"æœªçŸ¥çš„åœºæ™¯é€‰æ‹©æ¨¡å¼: {selection_mode}")
    else:
        scenarios = args.scenarios

    suffix = args.suffix or run_settings['default_suffix']

    # æ£€æŸ¥æ˜¯å¦å¯ç”¨å¹¶è¡Œæ¨¡å¼ï¼ˆå‘½ä»¤è¡Œå‚æ•°ä¼˜å…ˆï¼Œç„¶åæ˜¯é…ç½®æ–‡ä»¶ï¼‰
    parallel_enabled = args.parallel or parallel_settings['enabled']

    logger.info("ğŸš€ å¯åŠ¨ä¸­å¿ƒåŒ–å¤šæ™ºèƒ½ä½“ç¤ºä¾‹ï¼ˆæ”¯æŒé…ç½®è¦†ç›–ï¼‰")
    logger.info(f"ğŸ“‹ è¯„æµ‹æ¨¡å¼: {mode}")
    logger.info(f"ğŸ  åœºæ™¯é€‰æ‹©: {scenarios}")
    logger.info(f"ğŸ·ï¸ è¿è¡Œåç¼€: {suffix}")
    logger.info(f"âš™ï¸ é…ç½®æ–‡ä»¶: {args.config}")
    logger.info(f"ğŸ”„ å¹¶è¡Œæ¨¡å¼: {'å¯ç”¨' if parallel_enabled else 'ç¦ç”¨'}")
    logger.info(f"ğŸ¤– æ™ºèƒ½ä½“æ¶æ„: ä¸­å¿ƒåŒ–åè°ƒ (1ä¸ªåè°ƒå™¨æ§åˆ¶2ä¸ªæ™ºèƒ½ä½“)")

    # æ˜¾ç¤ºåº”ç”¨çš„é…ç½®è¦†ç›–
    if hasattr(config_manager, 'runtime_overrides') and config_manager.runtime_overrides:
        logger.info("ğŸ”§ åº”ç”¨çš„é…ç½®è¦†ç›–:")
        for config_name, overrides in config_manager.runtime_overrides.items():
            logger.info(f"   {config_name}: {overrides}")

    # å¦‚æœåªæ˜¯æ˜¾ç¤ºé…ç½®ï¼Œåˆ™æ‰“å°é…ç½®æ‘˜è¦å¹¶é€€å‡º
    if args.show_config:
        print_config_summary(args.config)
        print_config_summary('llm_config')
        return 0

    # æ£€æŸ¥æ˜¯å¦å¯ç”¨å¹¶è¡Œæ¨¡å¼
    if parallel_enabled:
        logger.info("ğŸ”„ å¹¶è¡Œæ¨¡å¼å·²å¯ç”¨ï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å¹¶è¡Œè®¾ç½®")

    # è¿è¡Œè¯„æµ‹
    return run_centralized_evaluation(args.config, mode, scenarios, suffix)


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
