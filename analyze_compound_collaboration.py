#!/usr/bin/env python3
"""
åˆ†æcompound_collaborationä»»åŠ¡çš„å¤±è´¥æƒ…å†µ
"""

import pandas as pd
import json
import os
from collections import defaultdict, Counter

def load_csv_data():
    """åŠ è½½CSVæ•°æ®"""
    csv_path = "raw_output/20250723_225455_multi_independent_00001_to_00600_qianduoduo_4o_wo_multi/subtask_execution_log.csv"
    
    if not os.path.exists(csv_path):
        print(f"âŒ CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
        return None
    
    df = pd.read_csv(csv_path)
    print(f"âœ… æˆåŠŸåŠ è½½CSVæ–‡ä»¶ï¼Œå…± {len(df)} æ¡è®°å½•")
    return df

def analyze_compound_collaboration_tasks(df):
    """åˆ†æcompound_collaborationä»»åŠ¡"""
    
    # ç­›é€‰compound_collaborationä»»åŠ¡
    compound_tasks = df[df['task_category'] == 'compound_collaboration'].copy()
    print(f"\nğŸ“Š compound_collaborationä»»åŠ¡æ€»æ•°: {len(compound_tasks)}")
    
    # ç»Ÿè®¡æˆåŠŸç‡
    status_counts = compound_tasks['status'].value_counts()
    print(f"\nğŸ“ˆ ä»»åŠ¡çŠ¶æ€åˆ†å¸ƒ:")
    for status, count in status_counts.items():
        percentage = (count / len(compound_tasks)) * 100
        print(f"  {status}: {count} ({percentage:.1f}%)")
    
    # åˆ†æå¤±è´¥ä»»åŠ¡
    failed_tasks = compound_tasks[compound_tasks['status'].isin(['failed', 'none'])].copy()
    print(f"\nâŒ å¤±è´¥ä»»åŠ¡æ•°é‡: {len(failed_tasks)} / {len(compound_tasks)} ({len(failed_tasks)/len(compound_tasks)*100:.1f}%)")
    
    return compound_tasks, failed_tasks

def analyze_failure_patterns(failed_tasks):
    """åˆ†æå¤±è´¥æ¨¡å¼"""
    print(f"\nğŸ” å¤±è´¥æ¨¡å¼åˆ†æ:")
    
    # æŒ‰subtask_completedåˆ†æ
    subtask_completed_counts = failed_tasks['subtask_completed'].value_counts()
    print(f"\nå­ä»»åŠ¡å®Œæˆæƒ…å†µ:")
    for completed, count in subtask_completed_counts.items():
        print(f"  subtask_completed={completed}: {count}")
    
    # æŒ‰model_claimed_doneåˆ†æ
    model_claimed_counts = failed_tasks['model_claimed_done'].value_counts()
    print(f"\næ¨¡å‹å£°ç§°å®Œæˆæƒ…å†µ:")
    for claimed, count in model_claimed_counts.items():
        print(f"  model_claimed_done={claimed}: {count}")
    
    # åˆ†æå‘½ä»¤æˆåŠŸç‡
    print(f"\nå‘½ä»¤æˆåŠŸç‡ç»Ÿè®¡:")
    print(f"  å¹³å‡å‘½ä»¤æˆåŠŸç‡: {failed_tasks['command_success_rate'].mean():.3f}")
    print(f"  æœ€ä½å‘½ä»¤æˆåŠŸç‡: {failed_tasks['command_success_rate'].min():.3f}")
    print(f"  æœ€é«˜å‘½ä»¤æˆåŠŸç‡: {failed_tasks['command_success_rate'].max():.3f}")
    
    # åˆ†æLLMäº¤äº’æ¬¡æ•°
    print(f"\nLLMäº¤äº’æ¬¡æ•°ç»Ÿè®¡:")
    print(f"  å¹³å‡äº¤äº’æ¬¡æ•°: {failed_tasks['llm_interactions'].mean():.1f}")
    print(f"  æœ€å°‘äº¤äº’æ¬¡æ•°: {failed_tasks['llm_interactions'].min()}")
    print(f"  æœ€å¤šäº¤äº’æ¬¡æ•°: {failed_tasks['llm_interactions'].max()}")

def load_task_and_scene_data(scenario_id):
    """åŠ è½½ä»»åŠ¡å’Œåœºæ™¯æ•°æ®"""
    task_path = f"data/eval/multi-independent/task/{scenario_id:05d}_task.json"
    scene_path = f"data/eval/multi-independent/scene/{scenario_id:05d}_scene.json"
    
    task_data = None
    scene_data = None
    
    if os.path.exists(task_path):
        with open(task_path, 'r', encoding='utf-8') as f:
            task_data = json.load(f)
    
    if os.path.exists(scene_path):
        with open(scene_path, 'r', encoding='utf-8') as f:
            scene_data = json.load(f)
    
    return task_data, scene_data

def load_trajectory_data(scenario_id):
    """åŠ è½½è½¨è¿¹æ•°æ®"""
    trajectory_path = f"raw_output/20250723_225455_multi_independent_00001_to_00600_qianduoduo_4o_wo_multi/trajectories/{scenario_id:05d}_trajectory.json"
    
    if os.path.exists(trajectory_path):
        with open(trajectory_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return None

def categorize_failure_reasons(failed_tasks):
    """åˆ†ç±»å¤±è´¥åŸå› """
    print(f"\nğŸ” å¤±è´¥åŸå› åˆ†ç±»:")

    failure_categories = {
        'low_command_success': [],  # å‘½ä»¤æˆåŠŸç‡ä½
        'model_false_positive': [],  # æ¨¡å‹è¯¯æŠ¥å®Œæˆ
        'timeout_failure': [],  # è¶…æ—¶å¤±è´¥
        'complex_task_failure': []  # å¤æ‚ä»»åŠ¡å¤±è´¥
    }

    for _, task in failed_tasks.iterrows():
        scenario_id = int(task['scenario_id'])

        # å‘½ä»¤æˆåŠŸç‡ä½äº50%
        if task['command_success_rate'] < 0.5:
            failure_categories['low_command_success'].append(scenario_id)

        # æ¨¡å‹å£°ç§°å®Œæˆä½†å®é™…æœªå®Œæˆ
        if task['model_claimed_done'] and not task['subtask_completed']:
            failure_categories['model_false_positive'].append(scenario_id)

        # LLMäº¤äº’æ¬¡æ•°è¾¾åˆ°ä¸Šé™(35æ¬¡)
        if task['llm_interactions'] >= 35:
            failure_categories['timeout_failure'].append(scenario_id)

        # ä»»åŠ¡æè¿°åŒ…å«å¤šä¸ªåŠ¨ä½œçš„å¤æ‚ä»»åŠ¡
        if 'and use' in task['task_description'] or 'then' in task['task_description']:
            failure_categories['complex_task_failure'].append(scenario_id)

    for category, scenarios in failure_categories.items():
        print(f"\n{category}: {len(scenarios)} ä¸ªä»»åŠ¡")
        if scenarios:
            print(f"  åœºæ™¯ID: {scenarios[:10]}{'...' if len(scenarios) > 10 else ''}")

    return failure_categories

def analyze_failed_task_details(failed_tasks):
    """è¯¦ç»†åˆ†æå¤±è´¥ä»»åŠ¡"""
    print(f"\nğŸ” å¤±è´¥ä»»åŠ¡è¯¦ç»†åˆ†æ:")
    print("=" * 80)

    # æŒ‰å¤±è´¥ä¸¥é‡ç¨‹åº¦æ’åºï¼ˆå‘½ä»¤æˆåŠŸç‡ä½çš„ä¼˜å…ˆï¼‰
    failed_tasks_sorted = failed_tasks.sort_values('command_success_rate').reset_index(drop=True)

    for idx in range(min(15, len(failed_tasks_sorted))):  # åˆ†æå‰15ä¸ªæœ€ä¸¥é‡çš„å¤±è´¥ä»»åŠ¡
        task = failed_tasks_sorted.iloc[idx]
        scenario_id = int(task['scenario_id'])

        print(f"\nğŸ“‹ å¤±è´¥ä»»åŠ¡ #{idx+1} (æŒ‰ä¸¥é‡ç¨‹åº¦æ’åº)")
        print(f"åœºæ™¯ID: {scenario_id:05d}")
        print(f"ä»»åŠ¡æè¿°: {task['task_description']}")
        print(f"çŠ¶æ€: {task['status']}")
        print(f"å­ä»»åŠ¡å®Œæˆ: {task['subtask_completed']}")
        print(f"æ¨¡å‹å£°ç§°å®Œæˆ: {task['model_claimed_done']}")
        print(f"å‘½ä»¤æˆåŠŸç‡: {task['command_success_rate']:.3f}")
        print(f"LLMäº¤äº’æ¬¡æ•°: {task['llm_interactions']}")
        print(f"æ‰§è¡Œæ—¶é•¿: {task['duration_seconds']:.1f}ç§’")

        # åŠ è½½ä»»åŠ¡å’Œåœºæ™¯æ•°æ®
        task_data, scene_data = load_task_and_scene_data(scenario_id)

        if task_data:
            print(f"\nğŸ“ ä»»åŠ¡è¯¦æƒ…:")
            if 'tasks' in task_data and len(task_data['tasks']) > 0:
                task_info = task_data['tasks'][0]  # é€šå¸¸ç¬¬ä¸€ä¸ªä»»åŠ¡
                print(f"  éªŒè¯æ£€æŸ¥: {task_info.get('validation_checks', [])}")

        if scene_data:
            print(f"\nğŸ  åœºæ™¯ä¿¡æ¯:")
            print(f"  åœºæ™¯åç§°: {scene_data.get('scene_name', 'N/A')}")
            print(f"  æ™ºèƒ½ä½“æ•°é‡: {len(scene_data.get('agents_config', []))}")

        # åŠ è½½è½¨è¿¹æ•°æ®
        trajectory_data = load_trajectory_data(scenario_id)
        if trajectory_data:
            print(f"\nğŸ›¤ï¸ è½¨è¿¹ä¿¡æ¯:")
            if 'tasks' in trajectory_data and len(trajectory_data['tasks']) > 0:
                task_trajectory = trajectory_data['tasks'][0]
                print(f"  æœ€ç»ˆçŠ¶æ€: {task_trajectory.get('final_status', 'N/A')}")
                if 'error_message' in task_trajectory:
                    print(f"  é”™è¯¯ä¿¡æ¯: {task_trajectory['error_message']}")

        print("-" * 60)

    if len(failed_tasks_sorted) > 15:
        print(f"\n... è¿˜æœ‰ {len(failed_tasks_sorted) - 15} ä¸ªå¤±è´¥ä»»åŠ¡æœªæ˜¾ç¤º")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” å¼€å§‹åˆ†æcompound_collaborationä»»åŠ¡å¤±è´¥æƒ…å†µ...")
    
    # åŠ è½½æ•°æ®
    df = load_csv_data()
    if df is None:
        return
    
    # åˆ†æcompound_collaborationä»»åŠ¡
    compound_tasks, failed_tasks = analyze_compound_collaboration_tasks(df)
    
    # åˆ†æå¤±è´¥æ¨¡å¼
    analyze_failure_patterns(failed_tasks)
    
    # è¯¦ç»†åˆ†æå¤±è´¥ä»»åŠ¡
    analyze_failed_task_details(failed_tasks)
    
    print(f"\nâœ… åˆ†æå®Œæˆï¼")

if __name__ == "__main__":
    main()
